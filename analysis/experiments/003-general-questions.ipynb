{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "In this experiment we are trying to differentiate between country-specific questions and ones which are more general (i.e. country-specific details need not be included in the response).\n",
    "We will use the best performing embedding and ChromaDB collection from the previous experiment (can be retrieved from MLFlow)."
   ],
   "id": "b409b6bda584ed79"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T13:20:13.091007Z",
     "start_time": "2024-07-14T13:20:12.022355Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import chromadb\n",
    "import requests\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pl\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "from tools import read_user_questions\n",
    "\n",
    "RUN_ID = '31e7999b-5e9c-4232-b1c8-58ebcabb53e4'\n",
    "EMBEDDING_URL = 'http://localhost:11434/api/embeddings'\n",
    "EMBEDDING_MODEL = 'mxbai-embed-large'\n",
    "\n",
    "CHROMA_DB_PATH = Path().resolve().parent / 'data' / 'chroma-db'\n",
    "\n",
    "USER_QUESTIONS_DIR = Path().resolve().parent / 'data' / 'user_questions'\n",
    "\n",
    "os.environ['LOGNAME'] = 'Michal Racko'"
   ],
   "id": "b05ce51614713639",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's load the ChromaDB collection from the previous experiment.",
   "id": "9be600425add0470"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T13:20:13.209838Z",
     "start_time": "2024-07-14T13:20:13.092040Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chroma_client = chromadb.PersistentClient(path=str(CHROMA_DB_PATH))\n",
    "collection = chroma_client.get_collection(f'company-documents-{RUN_ID}')"
   ],
   "id": "df3ebe42f2ca59df",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now we can load user questions corresponding to a specific country along with general ones. We'll use random subsampling to get a balanced dataset. If we wanted to use all the available country-specific questions, we'd need to calculate statistical weights associated with each class.",
   "id": "df3019bb77ffdfd2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T13:20:13.220223Z",
     "start_time": "2024-07-14T13:20:13.210576Z"
    }
   },
   "cell_type": "code",
   "source": [
    "user_questions = {\n",
    "    'country_specific': sum(\n",
    "        [\n",
    "            read_user_questions(\n",
    "                USER_QUESTIONS_DIR / f'{country}.txt',\n",
    "                n=100,\n",
    "                shuffle=True,\n",
    "                random_seed=42\n",
    "            ) for country in ('germany', 'italy', 'spain', 'sweden')\n",
    "        ],\n",
    "        start=[]\n",
    "    ),\n",
    "    'general': read_user_questions(USER_QUESTIONS_DIR / 'general.txt')\n",
    "}"
   ],
   "id": "62ad904dfe8899f2",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Calculate distances to the closest document and compare the corresponding distributions.",
   "id": "de6c3f43e56e042"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T13:20:14.370260Z",
     "start_time": "2024-07-14T13:20:13.221555Z"
    }
   },
   "cell_type": "code",
   "source": [
    "question_distances = {}\n",
    "for question_category, questions in user_questions.items():\n",
    "    question_distances[question_category] = []\n",
    "    for question in questions:\n",
    "        response = requests.post(\n",
    "            EMBEDDING_URL,\n",
    "            json={\n",
    "                'model': EMBEDDING_MODEL,\n",
    "                'prompt': question\n",
    "            }\n",
    "        )\n",
    "        results = collection.query(response.json()['embedding'], n_results=1)\n",
    "        question_distances[question_category].append(results['distances'][0][0])"
   ],
   "id": "7c4c0ad9d79a3ea4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [['Germany']],\n",
       " 'distances': [[290.9623443640898]],\n",
       " 'metadatas': [[None]],\n",
       " 'embeddings': None,\n",
       " 'documents': [['Reason: Market Saturation and Competition\\nThe German market is currently saturated with competitors offering similar products at lower prices. The high level of competition, combined with significant market entry barriers, makes it challenging to achieve a profitable market share. Consequently, we have decided to redirect our resources to more viable markets.']],\n",
       " 'uris': None,\n",
       " 'data': None,\n",
       " 'included': ['metadatas', 'documents', 'distances']}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T13:20:14.589420Z",
     "start_time": "2024-07-14T13:20:14.370868Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pl.figure(figsize=(16, 9))\n",
    "pl.hist(\n",
    "    [\n",
    "        question_distances['country_specific'],\n",
    "        question_distances['general']\n",
    "    ],\n",
    "    color=['tab:blue', 'tab:orange'],\n",
    "    label=['country_specific', 'general'],\n",
    "    bins=50\n",
    ")\n",
    "pl.legend(fontsize=16)\n",
    "pl.legend(fontsize=16)\n",
    "pl.xlabel('Distance to closest document', fontsize=16)\n",
    "pl.show()"
   ],
   "id": "7cb0bc11ea732a05",
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'general'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 5\u001B[0m\n\u001B[1;32m      1\u001B[0m pl\u001B[38;5;241m.\u001B[39mfigure(figsize\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m16\u001B[39m, \u001B[38;5;241m9\u001B[39m))\n\u001B[1;32m      2\u001B[0m pl\u001B[38;5;241m.\u001B[39mhist(\n\u001B[1;32m      3\u001B[0m     [\n\u001B[1;32m      4\u001B[0m         question_distances[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcountry_specific\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[0;32m----> 5\u001B[0m         \u001B[43mquestion_distances\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mgeneral\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[1;32m      6\u001B[0m     ],\n\u001B[1;32m      7\u001B[0m     color\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtab:blue\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtab:orange\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[1;32m      8\u001B[0m     label\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcountry_specific\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgeneral\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[1;32m      9\u001B[0m     bins\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m50\u001B[39m\n\u001B[1;32m     10\u001B[0m )\n\u001B[1;32m     11\u001B[0m pl\u001B[38;5;241m.\u001B[39mlegend(fontsize\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m16\u001B[39m)\n\u001B[1;32m     12\u001B[0m pl\u001B[38;5;241m.\u001B[39mlegend(fontsize\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m16\u001B[39m)\n",
      "\u001B[0;31mKeyError\u001B[0m: 'general'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x900 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can see the two distributions are neatly separated, so we can use a threshold to distinguish between country-specific and general questions. To find the optimal threshold we need to define a loss function that would be minimized. (1 - accuracy) will work just about well for this case given the balanced dataset.",
   "id": "424f0bd1ff267f9d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def loss(threshold: float,\n",
    "         distance_data: dict[str, list[float]],\n",
    "         bootstrap: bool = False) -> float:\n",
    "    \"\"\"\n",
    "    Calculates (1 - accuracy) of the question distribution for the given\n",
    "    the threshold which can be minimized to get the best-separating threshold.\n",
    "\n",
    "    :param distance_data:   data on question distance to the closest document,\n",
    "                            expected format:\n",
    "                                {\n",
    "                                    'country_specific': [<d0: float>, <d1: float>, ...>],\n",
    "                                    'general': [<d0: float>, <d1: float>, ...>]\n",
    "                                }\n",
    "    :param threshold:   threshold for which to calculate the loss\n",
    "    :param bootstrap:   whether to perform bootstrap sampling \n",
    "                        (see: https://en.wikipedia.org/wiki/Bootstrapping_(statistics))\n",
    "    :return: \n",
    "    \"\"\"\n",
    "    positive = np.array(distance_data['country_specific'])\n",
    "    negative = np.array(distance_data['general'])\n",
    "\n",
    "    if bootstrap:\n",
    "        positive = np.random.choice(positive, size=len(positive), replace=True)\n",
    "        negative = np.random.choice(negative, size=len(negative), replace=True)\n",
    "\n",
    "    return 1 - (\n",
    "            (positive <= threshold).sum() + (negative > threshold).sum()\n",
    "    ) / (len(positive) + len(negative))"
   ],
   "id": "ab6272907dc40be1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can use `scipy.optimize.minimize` to find the optimal threshold. Just need to make sure the fit converges well.",
   "id": "129c1517d667a7f9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "result = minimize(\n",
    "    partial(loss, distance_data=question_distances),\n",
    "    x0=300,\n",
    "    method='Nelder-Mead'\n",
    ")\n",
    "\n",
    "optimal_threshold = result.x[0]\n",
    "accuracy = 1 - result.fun\n",
    "\n",
    "print(f'Optimal threshold: {optimal_threshold:.2f}, accuracy: {accuracy * 100:.2f}%')"
   ],
   "id": "f90938143088681a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "pl.figure(figsize=(16, 9))\n",
    "counts, _, _ = pl.hist(\n",
    "    [\n",
    "        question_distances['country_specific'],\n",
    "        question_distances['general']\n",
    "    ],\n",
    "    color=['tab:blue', 'tab:orange'],\n",
    "    label=['country_specific', 'general'],\n",
    "    bins=50\n",
    ")\n",
    "pl.plot(\n",
    "    [optimal_threshold, optimal_threshold],\n",
    "    [0, max(counts.ravel())],\n",
    "    color='k',\n",
    "    linestyle='dashdot'\n",
    ")\n",
    "pl.legend(fontsize=16)\n",
    "pl.xlabel('Distance to closest document', fontsize=16)\n",
    "pl.show()"
   ],
   "id": "8ebfaf4381e237ee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Measurement without uncertainty is meaningless. As an example, if we tried to measure the width of a human hair, we'd get a solid zero. Does it mean the hair is infinitely thin? No, it just means that the measurement had been done using an instrument with accuracy of +-0.5mm, hence the real thickness is somewhere between 0 and 0.5mm (Physics rules out the negative half of the probability distribution).\n",
    "\n",
    "Something similar applies to the above measurement of the optimal threshold. Our dataset does not contain all the possible questions in each category but should rather be thought of as a (ideally random) sample from a distribution of all possible questions.\n",
    "\n",
    "Obviously there are many different variables which will have made it difficult to provide an accurate uncertainty estimate. Our dataset is almost certainly biased since we synthetically generated all the questions, some questions are repetitive, etc.\n",
    "\n",
    "What we can do is to try to use the random-sample hypothesis to provide some uncertainty estimate. So let's use the boostrap method."
   ],
   "id": "f9b53d4e1d2dedc3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "N_BOOTSTRAPS = 1000\n",
    "bootstrap_thresholds, bootstrap_accuracies = [], []\n",
    "for _ in range(N_BOOTSTRAPS):\n",
    "    result = minimize(\n",
    "        partial(loss, distance_data=question_distances, bootstrap=True),\n",
    "        x0=300,\n",
    "        method='Nelder-Mead'\n",
    "    )\n",
    "    bootstrap_thresholds.append(result.x[0])\n",
    "    bootstrap_accuracies.append(1 - result.fun)\n",
    "bootstrap_thresholds = np.array(bootstrap_thresholds)\n",
    "bootstrap_accuracies = np.array(bootstrap_accuracies)"
   ],
   "id": "417321ef82ae0724",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "pl.figure(figsize=(16, 9))\n",
    "pl.title('Bootstrap distribution', fontsize=20)\n",
    "pl.hist(bootstrap_thresholds, bins=20)\n",
    "pl.xlabel('threshold', fontsize=16)\n",
    "pl.show()"
   ],
   "id": "30a94765ab54cb32",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "pl.figure(figsize=(16, 9))\n",
    "pl.title('Bootstrap distribution', fontsize=20)\n",
    "pl.hist(bootstrap_accuracies, bins=20)\n",
    "pl.xlabel('accuracy', fontsize=16)\n",
    "pl.show()"
   ],
   "id": "ee7f3f786a4c459a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print('=== bootstrap results ===')\n",
    "print('- threshold:')\n",
    "print(\n",
    "    f'    mean: {bootstrap_thresholds.mean():.2f}, std: {bootstrap_thresholds.std():.2f}')\n",
    "print('- accuracy:')\n",
    "print(\n",
    "    f'    mean: {bootstrap_accuracies.mean() * 100:.2f}%, std: {bootstrap_accuracies.std() * 100:.2f}%')"
   ],
   "id": "5d7e5e9a58048817",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Conclusion\n",
    "\n",
    "These results can be interpreted this way:\n",
    "- Our best go on the threshold is 335\n",
    "- Roughly 6% of the questions will be misclassified (resulting e.g. in the chatbot providing country-specific policy, while the question did not ask for it)\n",
    "- If the ration of misclassified questions (in production over a longer period of time) rose over 8.15% (corresponding to 3 sigma deviation or just about 0.5% chance it being a random fluctuation), we'd need to get back to our analysis and update the threshold accordingly\n",
    "\n",
    "We can use MLFlow to keep track of production results"
   ],
   "id": "f77ec889b0a7512f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "48c9937493641252"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
